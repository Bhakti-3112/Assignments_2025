{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>q1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('image.png',)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "edges=cv2.Canny(blur,100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Gray Image\", gray)\n",
    "cv2.imshow(\"Gausian Blur Image\", blur)\n",
    "cv2.imshow(\"Canny Edges\", edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>q2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation=cv2.rotate(img,cv2.ROTATE_90_CLOCKWISE)\n",
    "scaling=cv2.resize(img,(500,250))\n",
    "flipping=cv2.flip(img,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Rotated Image\", rotation)\n",
    "cv2.imshow(\"Scaled Image\", scaling)\n",
    "cv2.imshow(\"Flipped Image\", flipping)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mmnist\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m      2\u001b[0m x_train \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      3\u001b[0m x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train/ 255.0\n",
    "x_test = x_test/ 255.0\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(x_train, y_train, epochs = 5, batch_size = 32, validation_split = 0.2)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0553 - accuracy: 0.9830\n",
      "Test Accuracy: 0.9830\n",
      "Test Loss: 0.0553\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test , y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Loss\")  \n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")  \n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection using Pre-Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 2 birds, 1 giraffe, 2 kites, 132.8ms\n",
      "Speed: 8.8ms preprocess, 132.8ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 416x640 1 potted plant, 2 clocks, 200.5ms\n",
      "Speed: 25.4ms preprocess, 200.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 448x640 5 bananas, 3 oranges, 209.5ms\n",
      "Speed: 34.7ms preprocess, 209.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "model_path = \"yolov8n.pt\"\n",
    "model = YOLO(model_path)\n",
    "\n",
    "def detect_objects(image_path, model):\n",
    "    image = cv2.imread(image_path)\n",
    "    results = model(image)\n",
    "    \n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            confidence = box.conf[0].item()\n",
    "            class_id = int(box.cls[0].item())\n",
    "            label = f\"{model.names[class_id]}: {confidence:.2f}\"\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1, 2)\n",
    "            cv2.rectangle(image, (x1, y1 - text_height - 5), (x1 + text_width, y1), (0, 255, 0), -1)   \n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Detected Objects\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "image_paths = [\"animals.jpg\", \"clumpsyroom.jpg\", \"image.png\"]\n",
    "for img in image_paths:\n",
    "    detect_objects(img, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, yolo basically divides image into grids and predicts boxes and class probabilities, thus helping to detect image and processes image using neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
