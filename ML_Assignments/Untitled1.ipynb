import tensorflow as tf
import matplotlib.pyplot as plt
import random
import numpy as np
from tensorflow import keras
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers, models
from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Dense, Flatten
from tensorflow.keras.preprocessing.image import ImageDataGenerator
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)
optimizer = Adam(learning_rate=0.001)
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D((2, 2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')  
])
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=5, batch_size=64)
history = model.fit(x_train, y_train, epochs=5, batch_size=64)
model.evaluate(x_test,y_test)
plt.figure(figsize=(12, 5))

# Plot Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss', color='blue')
plt.title('Training Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['acc'], label='Training Accuracy', color='green')
plt.title('Training Accuracy Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

import cv2
import os
from ultralytics import YOLO

# Initialize model and paths
model = YOLO("yolov8n.pt")  # Pre-trained YOLO model
image_paths = [
    "C:/Users/nishk/Downloads/Documents/free-photo-of-black-and-white-urban-street-scene-in-japan.jpeg",
    "C:/Users/nishk/Downloads/Documents/download (1).jpeg",
    "C:/Users/nishk/Downloads/Documents/download.jpeg"
]

output_dir = "YOLOresults"

# Create output directory if missing
os.makedirs(output_dir, exist_ok=True)

for image_path in image_paths:
    # Load image
    img = cv2.imread(image_path)
    if img is None:
        print(f"‚ö†Ô∏è Skipping missing image: {image_path}")
        continue

    print(f"üîç Processing: {os.path.basename(image_path)}")
    
    # Run object detection
    results = model(img)
    
    # Process detections
    for result in results:
        boxes = result.boxes.xyxy.cpu().numpy()
        labels = result.boxes.cls.cpu().numpy()
        conf_scores = result.boxes.conf.cpu().numpy()

        # Draw annotations
        for i, (box, label_idx, conf) in enumerate(zip(boxes, labels, conf_scores)):
            x1, y1, x2, y2 = map(int, box)
            label = model.names[int(label_idx)]
            
            # Draw bounding box and label
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img, 
                       f"{label}: {conf:.2f}", 
                       (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 
                       0.6, 
                       (0, 0, 255), 
                       2)

        # Save processed image
        output_path = os.path.join(output_dir, f"detected_{os.path.basename(image_path)}")
        cv2.imwrite(output_path, img)
        print(f"üíæ Saved results to: {output_path}")

# Display results summary
print("\nüéØ Detection Complete - Showing Results:")
for image_path in image_paths:
    result_path = os.path.join(output_dir, f"detected_{os.path.basename(image_path)}")
    img = cv2.imread(result_path)
    
    if img is not None:
        img = cv2.resize(img, (0, 0), fx=5, fy=5)
        cv2.imshow("Object Detection Preview", img)
        cv2.waitKey(0)  # Display each image for 2 seconds
    else:
        print(f"‚ö†Ô∏è Missing result file: {result_path}")

cv2.destroyAllWindows()
