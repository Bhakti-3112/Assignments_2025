{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section A: Image Processing Basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Load an image using OpenCV and perform the following operations:\n",
    "\n",
    "• Convert it to grayscale\n",
    "\n",
    "• Apply Gaussian blur\n",
    "\n",
    "• Detect edges using Canny edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries and Loading Image \n",
    "You need to run this cell at least once for other to work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "print(\"You are currently using \", cv2.__version__ , \" version of cv2\")\n",
    "\n",
    "image=cv2.imread(\"monster.jpeg\")\n",
    "# cv2 store image in bgr format instead of rgb format so we need to invert it for proper plotting in matplot\n",
    "cv2.imshow(\"Image original\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#i prefer matplotlib for output so i will be converting bgr to rgb for printing\n",
    "image_mat=image[:,:,::-1]\n",
    "fig,axes=plt.subplots(1,2)\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title(\"bgr and rgb are reversed due \\n to different format\")\n",
    "axes[1].imshow(image_mat)\n",
    "axes[1].set_title(\"Original Image\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_scale=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "fig,axes=plt.subplots(1,2)\n",
    "axes[0].imshow(gray_scale,cmap=\"gray\")\n",
    "axes[0].set_title(\"Gray Scaled\")\n",
    "axes[1].imshow(image_mat,cmap=\"gray\")\n",
    "axes[1].set_title(\"Original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Gaussian Blur, you can change the window size by change WINDOW_SIZE using inbuilt Gaussian Blur function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE=5\n",
    "blurred=cv2.GaussianBlur(gray_scale,(WINDOW_SIZE,WINDOW_SIZE),0)\n",
    "\n",
    "fig,axes=plt.subplots(1,2)\n",
    "axes[0].imshow(blurred,cmap=\"gray\")\n",
    "axes[0].set_title(\"Blurred\")\n",
    "axes[1].imshow(gray_scale,cmap=\"gray\")\n",
    "axes[1].set_title(\"Original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting edges  using inbuilt canny detect function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges=cv2.Canny(blurred,100,200)\n",
    "\n",
    "fig,axes=plt.subplots(1,2)\n",
    "axes[0].imshow(edges,cmap=\"gray\")\n",
    "axes[0].set_title(\"Edges\")\n",
    "axes[1].imshow(blurred,cmap=\"gray\")\n",
    "axes[1].set_title(\"Original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result can be seen through the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(2,2)\n",
    "axes[0][0].imshow(image_mat,cmap=\"gray\")\n",
    "axes[0][0].set_title(\"Original\")\n",
    "axes[0][1].imshow(gray_scale,cmap=\"gray\")\n",
    "axes[0][1].set_title(\"Applied grayscale\")\n",
    "axes[1][0].imshow(blurred,cmap=\"gray\")\n",
    "axes[1][0].set_title(\"Applied Gaussian blur\")\n",
    "axes[1][1].imshow(edges,cmap=\"gray\")\n",
    "axes[1][1].set_title(\"Applied Canny edge detection\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Perform image transformations such as rotation, scaling, and flipping using OpenCV. Display the\n",
    "original and transformed images.\n",
    "\n",
    "They all have inbuilt functions using them first\n",
    "You can change the First three variables as per convinience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALING_FACTOR=2\n",
    "FLIP=\"Horizontally\"\n",
    "ROTATE=\"ACW\"\n",
    "\n",
    "Flipcode={\n",
    "    \"Horizontally\" : 1 , \"Vertically\" : 0\n",
    "}\n",
    "\n",
    "Rotation={\n",
    "    \"CW\": cv2.ROTATE_90_CLOCKWISE,\"ACW\" : cv2.ROTATE_90_COUNTERCLOCKWISE\n",
    "}\n",
    "\n",
    "rotated_90=cv2.rotate(image_mat,Rotation[ROTATE])\n",
    "scaled=cv2.resize(image_mat,None,fx=SCALING_FACTOR,fy=SCALING_FACTOR)\n",
    "flipped=cv2.flip(image_mat,Flipcode[FLIP])\n",
    "\n",
    "fig,axes=plt.subplots(2,2)\n",
    "axes[0][0].imshow(image_mat,cmap=\"gray\")\n",
    "axes[0][0].set_title(\"Original\")\n",
    "axes[0][1].imshow(rotated_90,cmap=\"gray\")\n",
    "axes[0][1].set_title(\"Rotated\")\n",
    "axes[1][0].imshow(scaled,cmap=\"gray\")\n",
    "axes[1][0].set_title(\"Scaled\")\n",
    "axes[1][1].imshow(flipped,cmap=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section B: Image Classification using CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a CNN for Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import MNIST dataset by running the following cell first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(tf.__version__)\n",
    "\n",
    "(x_train,y_train), (x_test,y_test)=tf.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0\n",
    "\n",
    "model=tf.Sequential([\n",
    "    tf.layers.Conv2D(filters=32,kernel_size=(5,5),activation='relu',input_shape=(28,28,1)),\n",
    "    tf.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.layers.Flatten(),\n",
    "    tf.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "history = model.fit(x_train,y_train,epochs=10, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test , y_test, verbose=1)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "plt.plot(history.history[\"loss\"], label=\"Loss\")  \n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")  \n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section C: Object Detection using Pre-Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kindly import model once by running the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change or add the paths of the image to be detected by changing images path .( You need to run the follwing cell once to load images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path=[\"room.jpeg\",\"monster.jpeg\",\"rainy_night.jpeg\"]\n",
    "images=[cv2.imread(img) for img in images_path]\n",
    "results=model(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By playing the corresponding cell you can see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "plt.figure(figsize=(12,6))\n",
    "for r in results:\n",
    "    img=r.plot()\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(1,len(images_path),i)\n",
    "    plt.title(images_path[i-1].removesuffix(\".jpeg\").removesuffix(\"jpg\"))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section D: Detect Triangle inside a Circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use OpenCV API to detect shapes within an image, here triangles and circles.\n",
    "2. Implement logic to detect whether a triangle lies within another circle, if so, mark(with box or\n",
    "circle) both the circle and traingle. A triangle may lie within multiple circles.\n",
    "3. Submit atleast 3 images(testcases) validating your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: detecting circle using Hough circle method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(cv2.__version__)\n",
    "img=cv2.imread(\"circles.jpeg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "blurred=cv2.blur(gray,(3,3))\n",
    "canny=cv2.Canny(blurred,10,250)\n",
    "plt.imshow(canny,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_circles = cv2.HoughCircles(canny,cv2.HOUGH_GRADIENT,1,20,param1=30,param2=30,minRadius=50,maxRadius=100)\n",
    "if detected_circles is not None: \n",
    "    detected_circles=np.uint16(np.around(detected_circles))\n",
    "    for pt in detected_circles[0,:]: \n",
    "        a, b, r = pt[0], pt[1], pt[2] \n",
    "        cv2.circle(img, (a, b), r, (255, 255, 0), 2) \n",
    "        cv2.circle(img, (a, b), 1, (0, 0, 255), 3)\n",
    "\n",
    "plotable_img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n",
    "plt.imshow(plotable_img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: detecting line using Hough line detection method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting image in to usable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"triangles.jpeg\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "blurred=cv2.blur(gray,(3,3))\n",
    "canny=cv2.Canny(blurred,20,200)\n",
    "\n",
    "plt.imshow(canny,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting lines using inbuilt functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=cv2.HoughLinesP(canny,1,np.pi/180,50,minLineLength=2,maxLineGap=1)\n",
    "lines_list=list()\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2=line[0]\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(255,0,0),3)\n",
    "    lines_list.append([(x1,y1),(x2,y2)])\n",
    "\n",
    "plotable_img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(plotable_img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triangle detection\n",
    "(Method 1 : O(n<sup>3</sup>) approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_triangle(p1, p2, p3):\n",
    "    return (p1[0] * (p2[1] - p3[1]) +\n",
    "            p2[0] * (p3[1] - p1[1]) +\n",
    "            p3[0] * (p1[1] - p2[1])) != 0\n",
    "\n",
    "for i in range(len(lines_list)):\n",
    "    first_line = lines_list[i]\n",
    "\n",
    "    for j in range(i + 1, len(lines_list)):\n",
    "        second_line = lines_list[j]\n",
    "\n",
    "        common_point = set(first_line) & set(second_line)\n",
    "        if len(common_point) != 1:\n",
    "            continue\n",
    "        \n",
    "        common_point = list(common_point)[0]\n",
    "        remaining_points = set(first_line + second_line) - {common_point}\n",
    "\n",
    "        for k in range(j + 1, len(lines_list)):\n",
    "            third_line = lines_list[k]\n",
    "\n",
    "            if set(third_line) == remaining_points:\n",
    "                p1, p2, p3 = first_line[0], first_line[1], second_line[1]\n",
    "\n",
    "                if is_triangle(p1, p2, p3):\n",
    "                    cv2.line(img, p1, p2, (0, 0, 255), 3)\n",
    "                    cv2.line(img, p2, p3, (0, 0, 255), 3)\n",
    "                    cv2.line(img, p3, p1, (0, 0, 255), 3)\n",
    "\n",
    "plotable_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(plotable_img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found Out that above approach has some flaws since the end point are not exactly overlapping in detection so using other methods  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle detection using contour curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"triangles.jpeg\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "blur=cv2.blur(img,(3,3))\n",
    "canny=cv2.Canny(blur,10,250)\n",
    "\n",
    "contours , heirarchy = cv2.findContours(canny, cv2.RETR_EXTERNAL , cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for contour in contours:\n",
    "\n",
    "    epsilon=0.05 * cv2.arcLength(contour,True)\n",
    "    approx_poly=cv2.approxPolyDP(contour,epsilon,True)\n",
    "\n",
    "    if len(approx_poly)==3:\n",
    "        cv2.drawContours(img,[approx_poly],0,(0,0,255),3)\n",
    "\n",
    "plotable_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(plotable_img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Detecting triangle in a circle using contour curve ( combining all above methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting image\n",
    "img=cv2.imread(\"Screenshot 2025-03-28 123548.png\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "blur=cv2.GaussianBlur(gray,(9,9),2)\n",
    "canny=cv2.Canny(blur,50,200)\n",
    "\n",
    "#finding circles\n",
    "detected_circles = cv2.HoughCircles(canny,cv2.HOUGH_GRADIENT,1,20,param1=120,param2=30,minRadius=20,maxRadius=200)\n",
    "if detected_circles is not None: \n",
    "    detected_circles=np.uint16(np.around(detected_circles))\n",
    "\n",
    "#finding triangles\n",
    "contours , heirarchy = cv2.findContours(gray, cv2.RETR_TREE , cv2.CHAIN_APPROX_SIMPLE)\n",
    "for contour in contours:\n",
    "    epsilon=0.05 * cv2.arcLength(contour,True)\n",
    "    approx_poly=cv2.approxPolyDP(contour,epsilon,True)\n",
    "\n",
    "    if len(approx_poly)==3:\n",
    "        #checking if trinagle is in any circle\n",
    "        for circle in detected_circles[0,:]:\n",
    "            a,b,r=circle[0],circle[1],circle[2]\n",
    "            if all((pt[0]-a)**2 + (pt[1]-b)**2 <= r**2 for pt in approx_poly[:,0,:]):\n",
    "                #triangle detected inside a circle\n",
    "                cx,cy,re=cv2.minEnclosingCircle(approx_poly)\n",
    "                cv2.circle(img,(int(cx),int(cy)),int(re),(0,255,0),3)\n",
    "                cv2.circle(img,(a,b),r,(255,0,0),3)\n",
    "\n",
    "\n",
    "plotable_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(plotable_img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
