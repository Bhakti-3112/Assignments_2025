{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section A\n",
    "import cv2\n",
    "img = cv2.imread(r\"YOLOimages\\city.jpg\",1) #Reading the image\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #Converting to grayscale\n",
    "blurred = cv2.GaussianBlur(gray,(3,3),0) #Blurring\n",
    "edge = cv2.Canny(blurred, 100, 200, 5) #Detecting edges\n",
    "w,h=img.shape[:2]\n",
    "Ms = cv2.getRotationMatrix2D((w//2,h//2),0.0,2.0) #scale by 2x\n",
    "Mr = cv2.getRotationMatrix2D((w//2,h//2),39.0,1.0) #rotate by 39 degrees\n",
    "Mrs = cv2.getRotationMatrix2D((w//2,h//2),43.0,3.5) #rotate by 43 degrees and scale by 3.5x\n",
    "rotated = cv2.warpAffine(img, Mr, (w, h)) #rotated image\n",
    "scaled = cv2.warpAffine(img, Ms, (w, h)) #scaled image\n",
    "rot_n_scaled = cv2.warpAffine(img, Mrs, (w, h)) #applying both rotation and scaling\n",
    "#Displaying images\n",
    "cv2.imshow('Original',img)\n",
    "cv2.imshow('Grayed',gray)\n",
    "cv2.imshow('Blurred',blurred)\n",
    "cv2.imshow('Edges',edge)\n",
    "cv2.imshow('Rotated',rotated)\n",
    "cv2.imshow('Scaled',scaled)\n",
    "cv2.imshow('Rotated and Scaled',rot_n_scaled)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section B\n",
    "import tensorflow as tf\n",
    "#importing necessary functions\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#load mnist dataset\n",
    "(i_train,o_train),(i_test,o_test)=tf.keras.datasets.mnist.load_data()\n",
    "#normalise 0-255 to 0-1\n",
    "i_train=i_train/255.0\n",
    "i_test=i_test/255.0\n",
    "#reshape to match the input parameter dimensions for Conv2D function\n",
    "i_train=i_train.reshape(-1,28,28,1)\n",
    "i_test=i_test.reshape(-1,28,28,1) \n",
    "\"\"\"\n",
    "28,28 because the data loaded from mnist dataset has the dimensions 28,28 if we want it \n",
    "to be different we can resize the image beforehand after loading\n",
    "\"\"\"\n",
    "#labels to numbers(one-hot encoding)\n",
    "o_train=to_categorical(o_train,num_classes=10)\n",
    "o_test=to_categorical(o_test,num_classes=10)\n",
    "#split loaded training data into training and validation sets with test size being random 20%\n",
    "i_train,i_val,o_train,o_val=train_test_split(i_train,o_train,test_size=0.2,random_state=42)\n",
    "#we assign a seed(random state) so that the split is the same, \n",
    "# if split changes everytime then the diff in performnce could be due to different split rather than the changes made\n",
    "#model definition\n",
    "model=Sequential([\n",
    "    Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),#32 features, 3x3 kernel, activatioin mode is set to relu\n",
    "    #relu outputs zero for -ve inputs and out=in for +ve inputs\n",
    "    MaxPooling2D((2,2)), #Taking maximum value from 2x2 grid\n",
    "    #now the shape is (14,14)\n",
    "    Conv2D(64,(3,3),activation='relu'),#covolution with 64 features and same kernel size and activation method\n",
    "    MaxPooling2D((2,2)), #Maxpooling again\n",
    "    Flatten(), #Flatten into a 1D array\n",
    "    Dense(128,activation='relu'), #reduce the no. of element feature vectors to 128\n",
    "    Dropout(0.4), #randomly drops 40% of the 128 outputs to prevent overfitting\n",
    "    Dense(10, activation='softmax') #10 to match the number of output classes in MNIST dataset\n",
    "])\n",
    "#compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "#training the model\n",
    "history=model.fit(\n",
    "    i_train,o_train,\n",
    "    validation_data=(i_val,o_val),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "#Evaluation of loss and accuracy after training\n",
    "testloss,testaccu=model.evaluate(i_test,o_test,verbose=2)\n",
    "print(f\"Test Accuracy:{testaccu:.4f}\")\n",
    "#plotting  Accuracy vs Epochs and Loss vs Epochs\n",
    "plt.figure(figsize=(12, 4))\n",
    "#Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'],label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='Validation Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "#Loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'],label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],label='Validation Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#Testing and Visualising the prediction\n",
    "predictions=model.predict(i_test[:20])#the number can be increased by choice\n",
    "\n",
    "fig, axes=plt.subplots(2,10,figsize=(20,5))\n",
    "axes=axes.flatten()\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.imshow(i_test[i].reshape(28,28),cmap='gray')\n",
    "    ax.set_title(f\"Pred:{np.argmax(predictions[i])}\\nTrue:{np.argmax(o_test[i])}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section C\n",
    "#import necessary modules\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")#Pre-trained YOLO model\n",
    "image_paths = [\n",
    "    \"YOLOimages/room.jpg\",\n",
    "    \"YOLOimages/traffic.jpg\",\n",
    "    \"YOLOimages/study.jpg\"\n",
    "]\n",
    "output_dir=\"YOLOimages\"\n",
    "for images in image_paths:\n",
    "    img=cv2.imread(images)\n",
    "    if img is None:\n",
    "        print(f\"Image not found\")\n",
    "        continue\n",
    "    print(f\"Processing:{images}\")\n",
    "    print(f\"Image Size:{img.shape}\")\n",
    "    \n",
    "    results=model(img)\n",
    "    for result in results:\n",
    "        boxes=result.boxes.xyxy.cpu().numpy()\n",
    "        labels=result.boxes.cls.cpu().numpy()\n",
    "        confscore=result.boxes.conf.cpu().numpy()\n",
    "        \n",
    "        print(f\"Detected {len(boxes)} objects\")\n",
    "        \n",
    "        for i, box in enumerate(boxes):\n",
    "            x1,y1,x2,y2=map(int,box)\n",
    "            label=model.names[int(labels[i])]\n",
    "            confi=confscore[i]\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            cv2.putText(img,f\"{label}:{confi:.3f}\", (x1,y1-15),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),2)\n",
    "            print(f\"Object {i}:{label} at ({x1},{y1},{x2},{y2})\\n Confidence Score:{confi:.3f}\")\n",
    "            \n",
    "            output_path=os.path.join(output_dir,f\"detected_{os.path.basename(images)}\")\n",
    "            cv2.imwrite(output_path,img)\n",
    "            print(f\"Outout file saved at:{output_path}\")\n",
    "            \n",
    "new_images=[\n",
    "    \"YOLOimages/detected_room.jpg\",\n",
    "    \"YOLOimages/detected_study.jpg\",\n",
    "    \"YOLOimages/detected_traffic.jpg\"\n",
    "]\n",
    "for images in new_images:\n",
    "    img=cv2.imread(images)\n",
    "    cv2.imshow('Detection Results', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "print(\"We are done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
